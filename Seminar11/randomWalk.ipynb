{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Walk: TD vs MC comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we compare the performance of temporal difference (TD(0)) and Monte-Carlo.\n",
    "The example we consider is a so-called Markov reward process,\n",
    "i.e. a Markov decision process without actions.\n",
    "\n",
    "For a more detailed description see Example 6.2, page 125, in Sutton & Barto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is a finite, integer random walk of a given length,\n",
    "with the agent starting in the middle of the way.\n",
    "\n",
    "Each step they go left or right with equal probability.\n",
    "\n",
    "The two outermost states (`0` and `length-1`) are terminal.\n",
    "\n",
    "When the agent enters state `length-1` they receive a reward of +1, anytime else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RandomWalk:\n",
    "    def __init__(self, length):\n",
    "        self.length = length\n",
    "        self.pos = self.length // 2\n",
    "    \n",
    "    def step(self):\n",
    "        # ...\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        # ...\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the length of the random walk used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance and test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Monte-Carlo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a small helper function to check if a state is terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isTerminal(pos, length):\n",
    "    # ...\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the code for a single episode of MC.\n",
    "The value function is passed as `values` and updated in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def monteCarloEpisode(randomWalk: RandomWalk, values, alpha):\n",
    "    # Initialize new random walk etc.\n",
    "    # ...\n",
    "    \n",
    "    # Generate an episode\n",
    "    # ...\n",
    "    \n",
    "    # Update values\n",
    "    # ...\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform MC by running many episodes\n",
    "\n",
    "# ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TD(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the code for a single episode of TD(0).\n",
    "The value function is passed as `values` and updated in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tdEpisode(randomWalk: RandomWalk, values, alpha):\n",
    "    # Initialize new random walk\n",
    "    # ...\n",
    "\n",
    "    # Generate an episode, updating values in the process\n",
    "    # ...\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform TD(0) by running many episodes\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the true value of state $s$ is $s / (LENGTH - 1)$.\n",
    "We use this to compare the error made by each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_VALUES = [i / (LENGTH - 1) for i in range(LENGTH)]\n",
    "\n",
    "def computeRMS(values):\n",
    "    errors = [v - t for v, t in zip(values[1:-1], TRUE_VALUES[1:-1])]\n",
    "    return np.sqrt(np.mean(np.square(errors)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we recreate the left graph from p. 125, Sutton & Barto, showing the value function for different numbers of episodes $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotValueSteps(showN, alpha):\n",
    "    values = [0.5] * LENGTH\n",
    "    values[0] = 0\n",
    "    values[-1] = 0\n",
    "\n",
    "    randomWalk = RandomWalk(LENGTH)\n",
    "    \n",
    "    n = np.max(showN) + 1\n",
    "    \n",
    "    # Perform TD, plotting the values of steps in showN\n",
    "    # ...\n",
    "    \n",
    "    plt.plot(TRUE_VALUES[1:-1], linestyle='dashdot', label=\"true values\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotValueSteps([0, 1, 10, 100], 0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function that performs several TD/MC episodes and computes the RMS after each episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeRMSs(alpha, nEpisodes, xxxEpisode):\n",
    "    randomWalk = RandomWalk(LENGTH)\n",
    "    rms = []\n",
    "    values = [0.5] * LENGTH\n",
    "    values[0] = 0\n",
    "    values[-1] = 0\n",
    "    for j in range(nEpisodes):\n",
    "        xxxEpisode(randomWalk, values, alpha)\n",
    "        rms.append(computeRMS(values))\n",
    "    return rms\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function above,\n",
    "we plot the RMS vs. the number of training episodes for both methods and different values of `alpha`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def movingAverage(a, k):\n",
    "    return np.convolve(a, np.ones(k), 'valid') / k\n",
    "\n",
    "# Compared alphas\n",
    "alphasMC = [0.01, 0.02, 0.03, 0.04]\n",
    "alphasTD = [0.01, 0.05, 0.10, 0.20]\n",
    "\n",
    "# Number of episodes per experiment\n",
    "nEpisodes = 200\n",
    "\n",
    "# Number of experiments\n",
    "nExperiments = 100\n",
    "\n",
    "print('MC...')\n",
    "for i, alpha in enumerate(alphasMC):\n",
    "    print(alpha)\n",
    "    rmsList = [computeRMSs(alpha, nEpisodes, monteCarloEpisode) for _ in range(nExperiments)]\n",
    "    rms = np.mean(rmsList, axis=0)\n",
    "    plt.plot(rms, linestyle='dashdot', label='MC {}'.format(alpha))\n",
    "\n",
    "print('TD...')\n",
    "for i, alpha in enumerate(alphasTD):\n",
    "    print(alpha)\n",
    "    rmsList = [computeRMSs(alpha, nEpisodes, tdEpisode) for _ in range(nExperiments)]\n",
    "    rms = np.mean(rmsList, axis=0)\n",
    "    plt.plot(rms, linestyle='solid', label='TD {}'.format(alpha))\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "275c90bd5bb82664c788af040251692cc03dc86a881c38c70c21622899dbd0c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
